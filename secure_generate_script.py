import os
import logging
import openai
from openai_manager import openai_manager
from quota_manager import quota_manager
from typing import Optional, Dict, Any
from datetime import datetime

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('static/logs/script_generation.log'),
        logging.StreamHandler()
    ]
)

class ScriptGenerator:
    def __init__(self):
        self.max_retries = 3
        self.fallback_models = ['gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-4', 'gpt-4-1106-preview']
        self.default_model = 'gpt-3.5-turbo'

    def _get_openai_client(self, api_key: str):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        return openai.OpenAI(
            api_key=api_key,
            timeout=30.0,
            max_retries=3
        )

    def _estimate_token_usage(self, text: str) -> int:
        """ëŒ€ëµì ì¸ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì • (ê°„ë‹¨í•œ ë²„ì „)"""
        return len(text) // 4  # ëŒ€ëµì ì¸ ì¶”ì •

    def generate_script(self, trend_data: Dict[str, Any], target_duration: int = 60) -> Optional[str]:
        """íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        topic = trend_data.get('topic', 'ì¸ê¸° ìˆëŠ” ê¸°ìˆ  íŠ¸ë Œë“œ')
        category = trend_data.get('category', 'ê¸°ìˆ ')
        score = trend_data.get('score', 50)
        
        prompt = f"""
        ì£¼ì œ: "{topic}" (ì¹´í…Œê³ ë¦¬: {category}, ì¸ê¸° ì ìˆ˜: {score}/100)

        ìš”ì²­: ìœ„ ì£¼ì œì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ í•œêµ­ì–´ ìœ íŠœë¸Œ ì‡¼ì¸ (Shorts) ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
        - ì´ ê¸¸ì´: ì •í™•íˆ {target_duration}ì´ˆ (ì•½ 150-200ë‹¨ì–´)
        - ëŒ€ìƒ: ì¼ë°˜ ì‹œì²­ì (ì „ë¬¸ ìš©ì–´ ìµœì†Œí™”)
        - í†¤: ì¹œê·¼í•˜ê³  ì¬ë¯¸ìˆê²Œ
        - êµ¬ì¡°:
          1. í›… (3-5ì´ˆ): ê°•ë ¬í•œ ì‹œì‘
          2. ë³¸ë¬¸ (40-50ì´ˆ): í•µì‹¬ ë‚´ìš© 2-3ê°€ì§€
          3. ê²°ë¡  (5-7ì´ˆ): ìš”ì•½ ë° CTA
        - ì¶”ê°€ ìš”êµ¬ì‚¬í•­:
          - ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš© (ì˜ˆ: ğŸ”¥, ğŸ¤–, ï¿½ï¿½)
          - ë¬¸ì¥ì€ ì§§ê³  ê°„ê²°í•˜ê²Œ
          - ìˆ«ì/ì‚¬ë¡€ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
          #í•´ì‹œíƒœê·¸ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
        """

        for attempt in range(self.max_retries):
            try:
                api_key = openai_manager.get_valid_key()
                client = self._get_openai_client(api_key)
                model = self._select_model(attempt)

                logging.info(f"ì‹œë„ {attempt + 1}: '{topic}' ì£¼ì œë¡œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (ëª¨ë¸: {model})")

                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì‡¼ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  í¥ë¯¸ë¡œìš´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=800,
                    top_p=0.9
                )

                script = response.choices[0].message.content.strip()
                token_usage = self._estimate_token_usage(prompt + script)

                # ì¿¼í„° ì—…ë°ì´íŠ¸
                quota_manager.update_usage('openai', token_usage // 1000 + 1, api_key)

                logging.info(f"ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì„±ê³µ! (ê¸¸ì´: {len(script)}ì, ì˜ˆìƒ í† í°: ~{token_usage})")
                return script

            except openai.RateLimitError:
                logging.warning(f"ì‹œë„ {attempt + 1}: API Rate Limit ë„ë‹¬. í‚¤ ë³€ê²½ ì¤‘...")
                openai_manager.report_key_failure(api_key)
                continue
            except openai.APIError as e:
                logging.error(f"ì‹œë„ {attempt + 1}: OpenAI API ì˜¤ë¥˜: {str(e)}")
                if attempt == self.max_retries - 1:
                    raise
                continue
            except Exception as e:
                logging.error(f"ì‹œë„ {attempt + 1}: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
                if attempt == self.max_retries - 1:
                    raise
                continue

        logging.error("ëª¨ë“  ì‹œë„ ì‹¤íŒ¨. ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ë¶ˆê°€")
        return None

    def _select_model(self, attempt: int) -> str:
        """ì¬ì‹œë„ íšŸìˆ˜ì— ë”°ë¼ ëª¨ë¸ ì„ íƒ"""
        if attempt == 0:
            return self.default_model
        return self.fallback_models[min(attempt, len(self.fallback_models) - 1)]

# ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤
script_generator = ScriptGenerator()

if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    
    test_trend = {
        'topic': 'AIì˜ ë¯¸ë˜ì™€ ì¼ìë¦¬',
        'category': 'ê¸°ìˆ ',
        'score': 85
    }
    
    try:
        script = script_generator.generate_script(test_trend)
        print("\n=== ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ ===")
        print(script)
        print("\n=== ìŠ¤í¬ë¦½íŠ¸ í†µê³„ ===")
        print(f"ê¸¸ì´: {len(script)}ì")
        print(f"ì¤„ ìˆ˜: {len(script.splitlines())}")
    except Exception as e:
        print(f"ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
